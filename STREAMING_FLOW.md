# Streaming Architecture Flow

## Request Flow with New Configuration

```
User Request
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ inputer_node (Router)                                      â”‚
â”‚ LLM: llm (non-streaming)                                   â”‚
â”‚ Output: RouterDecision (Pydantic)                          â”‚
â”‚ Returns: Complete JSON immediately                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ search_agent_node                                          â”‚
â”‚ LLM: llm (non-streaming)                                   â”‚
â”‚ Output: AgentCheck (Pydantic)                              â”‚
â”‚ Returns: Complete JSON immediately                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ planner_node                                               â”‚
â”‚ LLM: llm (non-streaming)                                   â”‚
â”‚ Output: Plan (Pydantic with steps)                         â”‚
â”‚ Returns: Complete JSON immediately                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ task_dispatcher_node                                       â”‚
â”‚ LLM: llm (non-streaming)                                   â”‚
â”‚ Output: Router (Pydantic)                                  â”‚
â”‚ Returns: Complete JSON immediately                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ supervisor_node (if needed)                                â”‚
â”‚ LLM: llm (non-streaming)                                   â”‚
â”‚ Output: Router (Pydantic)                                  â”‚
â”‚ Returns: Complete JSON immediately                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent Execution (gmail/instagram/youtube/research)         â”‚
â”‚ LLM: llm (non-streaming)                                   â”‚
â”‚ Output: Tool calls & structured data                       â”‚
â”‚ Returns: Complete JSON immediately                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ final_answer_node                                          â”‚
â”‚ LLM: stream_llm (STREAMING âœ¨)                             â”‚
â”‚ Output: Natural language response                          â”‚
â”‚ Returns: Token-by-token stream                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
User sees streaming response
```

## Frontend Receives

### During Workflow (non-streaming nodes)
```json
{
  "stream_type": "updates",
  "event": "delta",
  "data": {
    "node": "planner_node",
    "status": "success",
    "next_node": "task_dispatcher_node",
    "message": "Complete message here",
    "plans": ["Step 1", "Step 2"]
  }
}
```
âœ… **Complete JSON objects** - No character-by-character assembly needed!

### Final Answer (streaming node)
```
event: delta
data: {"stream_type": "messages", "message": "Here"}

event: delta
data: {"stream_type": "messages", "message": " is"}

event: delta
data: {"stream_type": "messages", "message": " your"}

event: delta
data: {"stream_type": "messages", "message": " answer"}
```
âœ… **Token-by-token streaming** - Natural typing effect!

## Key Differences

| Aspect | Old Behavior | New Behavior |
|--------|--------------|--------------|
| Router decisions | Streamed char-by-char | Complete JSON |
| Plan generation | Streamed char-by-char | Complete JSON |
| Agent responses | Streamed char-by-char | Complete JSON |
| Final answer | Streamed char-by-char | âœ… Still streams |
| Frontend parsing | Complex reassembly | Direct JSON parse |
| Performance | Slower (many small msgs) | Faster (fewer msgs) |

## Code Examples

### Old Way (Everything Streams)
```python
# âŒ Problem: JSON streams character by character
llm = init_chat_model("openai:gpt-4o-mini")  # Default streaming
decision = llm.with_structured_output(Router).invoke(messages)
# Frontend receives: { " n " e " x " t " : ...
```

### New Way (Selective Streaming)
```python
# âœ… Structured output: Complete JSON
llm = ChatOpenAI(streaming=False)  # Non-streaming
decision = llm.with_structured_output(Router).invoke(messages)
# Frontend receives: {"next": "agent_name", "reason": "..."}

# âœ… Final answer: Token streaming
stream_llm = ChatOpenAI(streaming=True)  # Streaming
final = stream_llm.invoke(messages)
# Frontend receives: Token ... by ... token
```

## Benefits Summary

1. ğŸ¯ **Cleaner API**: Structured data as complete objects
2. âš¡ **Better Performance**: Fewer network messages
3. ğŸ” **Easier Debugging**: Can log complete decisions
4. ğŸ¨ **Better UX**: Final answers still stream naturally
5. ğŸ›¡ï¸ **Type Safety**: Pydantic validation works correctly
6. ğŸ“Š **Predictable**: Know exactly when data is complete
